# -*- coding: utf-8 -*-
"""Copy of Batch15-IT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JjtjV3LiiT5ygavqK1hpKvZr8h16K63i
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras import backend as K
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input, decode_predictions
from keras.models import Model

import warnings
from keras.applications.vgg16 import VGG16
from keras.models import Model
warnings.filterwarnings('ignore')
from keras.applications.vgg16 import preprocess_input

img_width, img_height = 64, 64
train_size, validation_size,test_size = 6730, 556 ,640
train_path='/content/drive/My Drive/data2/data/data_train'
validation_path='/content/drive/My Drive/data2/data/data_val'
img_path='/content/drive/My Drive/data2/data/w_test.png'

PTmodel = VGG16(weights='imagenet',include_top=False,input_shape=(img_width, img_height, 3))
print(PTmodel.summary())

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1./255)
batch_size = 32

def extract_features(directory, sample_count):
    features = np.zeros(shape=(sample_count, 2, 2, 512))  # Must be equal to the output of the convolutional base
    labels = np.zeros(shape=(sample_count))
    # Preprocess data
    generator = datagen.flow_from_directory(directory,
                                            target_size=(img_width,img_height),
                                            batch_size = batch_size,
                                            class_mode='binary')
    # Pass data through convolutional base
    i = 0
    for inputs_batch, labels_batch in generator:
        features_batch = PTmodel.predict(inputs_batch)
        features[i * batch_size: (i + 1) * batch_size] = features_batch
        labels[i * batch_size: (i + 1) * batch_size] = labels_batch
        i += 1
        if i * batch_size >= sample_count:
            break
    return features, labels

train_features, train_labels = extract_features(train_path, train_size)  # Agree with our small dataset size
validation_features, validation_labels = extract_features(validation_path, validation_size)

from keras import models
from keras import layers
from keras import optimizers

epochs = 100

Cmodel = models.Sequential()
Cmodel.add(layers.Flatten(input_shape=(2,2,512)))
Cmodel.add(layers.Dropout(0.5))
Cmodel.add(layers.Dense(256, activation='relu', input_dim=(7*7*512)))
Cmodel.add(layers.Dropout(0.5))
Cmodel.add(layers.Dense(1, activation='sigmoid'))
Cmodel.summary()

Cmodel.compile(optimizer=optimizers.SGD(lr = 0.01 ),
              loss='binary_crossentropy',
              metrics=['acc'])

history = Cmodel.fit(train_features, train_labels,
                    epochs=epochs,
                    batch_size=batch_size, 
                    validation_data=(validation_features, validation_labels))

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc)+1)

plt.plot(epochs, acc,'--', label='Training accuracy')
plt.plot(epochs, val_acc, label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss,'--',label='Training loss')
plt.plot(epochs, val_loss, label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

plt.plot(history.history['acc'],'--')
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['loss'],'--')
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

img = image.load_img(img_path, target_size=(img_width, img_height))
img_tensor = image.img_to_array(img)  # Image data encoded as integers in the 0â€“255 range
img_tensor /= 255.  # Normalize to [0,1] for plt.imshow applic
features = PTmodel.predict(img_tensor.reshape(1,img_width, img_height, 3))

#@title Test Prediction
try:
    prediction = Cmodel.predict(features)
except:
    prediction = Cmodel.predict(features.reshape(1, 7*7*512))

# Show picture
plt.imshow(img_tensor)
plt.show()

# Write prediction
if prediction < 0.5:
    print('Plant')
else:
    print('Weed')